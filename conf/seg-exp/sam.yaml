logger:
  class_path: lightning.pytorch.loggers.WandbLogger
  init_args:
    name: sam
    save_dir: output/seg-exp
    project: MMMM
data:
  patch_size: [96, 224, 224]
  dataloader:
    train_batch_size: 8
model:
  sam:
    pos_embed_shape: [6, 14, 14]
    pt_in_channels: 1
    pt_patch_size: [4, 16, 16]
    pt_pos_embed_shape: [8, 16, 16]
    checkpoint: pre-trained/SegVol_v1.pth
trainer: trainer.yaml
optimization:
- optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-4
      weight_decay: 5e-2
  lr_scheduler:
    scheduler:
      class_path: timm.scheduler.CosineLRScheduler
      init_args:
        t_initial: ${trainer.max_steps}
        t_in_epochs: false
        warmup_t: 0
        warmup_prefix: true
    interval: step
    frequency: 200
