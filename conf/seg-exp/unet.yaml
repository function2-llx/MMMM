logger:
  class_path: lightning.pytorch.loggers.WandbLogger
  init_args:
    name: unet
    save_dir: output/seg-exp
    project: MMMM
data:
  patch_size: [64, 192, 192]
  dataloader:
    train_batch_size: 8
model:
  backbone:
    class_path: luolib.models.UNetBackbone
    init_args:
      spatial_dims: 3
      in_channels: 3
      layer_channels: [32, 64, 128, 256, 320, 320]
      kernel_sizes:
      - [1, 3, 3]
      - [1, 3, 3]
      - 3
      - 3
      - 3
      - 3
      strides:
      - 1
      - [1, 2, 2]
      - 2
      - 2
      - 2
      - 2
      num_blocks: 2
      res_block: true
  decoder:
    class_path: luolib.models.PlainConvUNetDecoder
    init_args:
      spatial_dims: 3
      layer_channels: ${...backbone.init_args.layer_channels}
      kernel_sizes: ${...backbone.init_args.kernel_sizes}
      strides: ${...backbone.init_args.strides}
      res_block: true
trainer:
  max_steps: 60000
  log_every_n_steps: 10
  precision: bf16-true
  gradient_clip_val: 10
  gradient_clip_algorithm: norm
  callbacks:
  - class_path: luolib.lightning.callbacks.ModelCheckpoint
    init_args:
      every_n_train_steps: 1000
      filename: "{step}"
      save_top_k: -1
      save_last: true
      verbose: true
optimization:
- optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-4
      weight_decay: 5e-2
  lr_scheduler:
    scheduler:
      class_path: timm.scheduler.CosineLRScheduler
      init_args:
        t_initial: ${trainer.max_steps}
        t_in_epochs: false
        warmup_t: 0
        warmup_prefix: true
    interval: step
    frequency: 200
