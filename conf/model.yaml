model:
  class_path: mmmm.models.build
  init_args:
    pretrained_model_name_or_path: THUDM/cogvlm-chat-hf
    vision_override:
      patch_size: 16
      pos_embed_shape: [8, 24, 24]
      pt_pos_embed_shape: [35, 35]
    lora_lang: true
    sam:
      patch_size: 16
      pos_embed_shape: [8, 24, 24]
      pt_in_channels: 1
      pt_patch_size: [4, 16, 16]
      pt_pos_embed_shape: [8, 16, 16]
      num_instances: 6
      checkpoint: pre-trained/SegVol_v1.pth
lora:
  r: 64
  lora_alpha: 8
  lora_dropout: 0.05
  use_rslora: true
